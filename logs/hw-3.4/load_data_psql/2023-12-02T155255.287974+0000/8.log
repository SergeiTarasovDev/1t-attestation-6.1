[2023-12-02 16:31:29,592] {{taskinstance.py:670}} INFO - Dependencies all met for <TaskInstance: hw-3.4.load_data_psql 2023-12-02T15:52:55.287974+00:00 [queued]>
[2023-12-02 16:31:29,709] {{taskinstance.py:670}} INFO - Dependencies all met for <TaskInstance: hw-3.4.load_data_psql 2023-12-02T15:52:55.287974+00:00 [queued]>
[2023-12-02 16:31:29,712] {{taskinstance.py:880}} INFO - 
--------------------------------------------------------------------------------
[2023-12-02 16:31:29,714] {{taskinstance.py:881}} INFO - Starting attempt 8 of 8
[2023-12-02 16:31:29,716] {{taskinstance.py:882}} INFO - 
--------------------------------------------------------------------------------
[2023-12-02 16:31:29,747] {{taskinstance.py:901}} INFO - Executing <Task(PythonOperator): load_data_psql> on 2023-12-02T15:52:55.287974+00:00
[2023-12-02 16:31:29,756] {{standard_task_runner.py:54}} INFO - Started process 1653 to run task
[2023-12-02 16:31:29,853] {{standard_task_runner.py:77}} INFO - Running: ['airflow', 'run', 'hw-3.4', 'load_data_psql', '2023-12-02T15:52:55.287974+00:00', '--job_id', '17', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/hw-3.4.py', '--cfg_path', '/tmp/tmpdsgadjf1']
[2023-12-02 16:31:29,856] {{standard_task_runner.py:78}} INFO - Job 17: Subtask load_data_psql
[2023-12-02 16:31:29,917] {{logging_mixin.py:120}} INFO - Running <TaskInstance: hw-3.4.load_data_psql 2023-12-02T15:52:55.287974+00:00 [running]> on host 2cf373442eb7
[2023-12-02 16:31:29,958] {{base_hook.py:89}} INFO - Using connection to: id: conn1. Host: host.docker.internal, Port: 5434, Schema: quotes, Login: postgres, Password: XXXXXXXX, extra: None
[2023-12-02 16:31:32,404] {{logging_mixin.py:120}} INFO - ------------ response --------------
[2023-12-02 16:31:32,415] {{logging_mixin.py:120}} INFO - https://www.alphavantage.co/query?function=SYMBOL_SEARCH&apikey=PO8LZ4A0I0PPI60J&keywords=intel%2C+ibm
[2023-12-02 16:31:32,417] {{logging_mixin.py:120}} INFO - None
[2023-12-02 16:31:32,435] {{logging_mixin.py:120}} INFO - {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}
[2023-12-02 16:31:32,455] {{logging_mixin.py:120}} INFO - ------------ end --------------
[2023-12-02 16:31:32,469] {{logging_mixin.py:120}} INFO - ------------ data --------------
[2023-12-02 16:31:32,471] {{logging_mixin.py:120}} INFO - {'bestMatches': []}
[2023-12-02 16:31:32,481] {{logging_mixin.py:120}} INFO - ------------ end --------------
[2023-12-02 16:31:32,483] {{taskinstance.py:1150}} ERROR - Ошибка записи данных: 'timestamp'
Traceback (most recent call last):
  File "/usr/local/airflow/dags/modules/functions.py", line 70, in load_data_psql
    get_date = datetime.utcfromtimestamp(data["timestamp"]).strftime('%Y-%m-%d %H:%M:%S')
KeyError: 'timestamp'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 984, in _run_raw_task
    result = task_copy.execute(context=context)
  File "/usr/local/lib/python3.7/site-packages/airflow/operators/python_operator.py", line 113, in execute
    return_value = self.execute_callable()
  File "/usr/local/lib/python3.7/site-packages/airflow/operators/python_operator.py", line 118, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/usr/local/airflow/dags/modules/functions.py", line 83, in load_data_psql
    raise Exception(f'Ошибка записи данных: {error}')
Exception: Ошибка записи данных: 'timestamp'
[2023-12-02 16:31:32,497] {{taskinstance.py:1194}} INFO - Marking task as FAILED. dag_id=hw-3.4, task_id=load_data_psql, execution_date=20231202T155255, start_date=20231202T163129, end_date=20231202T163132
[2023-12-02 16:31:34,555] {{local_task_job.py:102}} INFO - Task exited with return code 1
